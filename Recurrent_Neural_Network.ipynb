{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQmL+q+gfjYLVz4FQsbjvV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhotNoorin/Deep-Learning/blob/main/Recurrent_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Network (RNN) in Deep Learning\n",
        "\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are a class of neural networks that are well-suited for processing sequential data such as time series, natural language, audio, and video. Unlike traditional feedforward neural networks, RNNs have connections that form directed cycles, allowing them to maintain a hidden state and capture temporal dependencies.\n",
        "\n",
        "\n",
        "- **Sequential Processing**: RNNs process inputs one step at a time, maintaining a memory (hidden state) of previous steps.\n",
        "- **Hidden State**: The hidden state acts as the memory of the network, enabling it to carry information across timesteps.\n",
        "- **Weights Sharing**: The same weights are applied at each timestep, which reduces the number of parameters and enables learning from sequences of arbitrary lengths.\n",
        "- **Backpropagation Through Time (BPTT)**: The training algorithm used for RNNs is a modified version of backpropagation that accounts for the sequential nature of data.\n",
        "\n",
        "## RNN Architecture\n",
        "\n",
        "At each timestep t, the RNN performs the following computations:\n",
        "\n",
        "- Hidden state update:\n",
        "  \\[\n",
        "  h_t = \\tanh(W_{xh} \\cdot x_t + W_{hh} \\cdot h_{t-1} + b_h)\n",
        "  \\]\n",
        "\n",
        "- Output (optional):\n",
        "  \\[\n",
        "  y_t = W_{hy} \\cdot h_t + b_y\n",
        "  \\]\n",
        "\n",
        "Where:\n",
        "- \\( x_t \\): input at time t\n",
        "- \\( h_t \\): hidden state at time t\n",
        "- \\( W_{xh}, W_{hh}, W_{hy} \\): weight matrices\n",
        "- \\( b_h, b_y \\): bias terms\n",
        "\n",
        "## Applications\n",
        "\n",
        "- Natural Language Processing (NLP): text generation, sentiment analysis, translation\n",
        "- Time Series Forecasting: stock price prediction, weather forecasting\n",
        "- Speech Recognition\n",
        "- Music Generation\n",
        "\n",
        "## Disadv\n",
        "\n",
        "- **Vanishing/Exploding Gradients**: During BPTT, gradients can shrink or grow exponentially, making training unstable for long sequences.\n",
        "- **Short-Term Memory**: Standard RNNs struggle to capture long-range dependencies.\n",
        "\n",
        "## Solutions to RNN\n",
        "\n",
        "To address the limitations of standard RNNs, advanced architectures were developed:\n",
        "- **Long Short-Term Memory (LSTM)**\n",
        "- **Gated Recurrent Unit (GRU)**\n",
        "\n",
        "These architectures introduce gates to better control the flow of information and retain memory over longer sequences.\n",
        "\n",
        "## Summary\n",
        "\n",
        "RNNs are foundational models for sequence data in deep learning. While they have limitations with long-term dependencies, they serve as a basis for more advanced recurrent models like LSTMs and GRUs, which have significantly improved performance in many applications.\n"
      ],
      "metadata": {
        "id": "-ryxifS0X4fc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-XZvp6ldX34i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 1000\n",
        "sequence_length = 5\n",
        "vocab_size = 11  # (1 to 10)\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "R4-syhuuYahO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randint(1, vocab_size, size=(num_samples, sequence_length))\n",
        "y = np.sum(X, axis=1) % num_classes  # simple rule to create binary labels\n",
        "y = to_categorical(y, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "7OD8vU7QYcyf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "xQ5O2gF8Ye3P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=8, input_length=sequence_length))\n",
        "model.add(SimpleRNN(units=32, activation='tanh'))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUGliWhGYhzm",
        "outputId": "e430733e-4c19-42ce-d646-1d849ce1e4ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8o2J9v_2Yk1L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRQEhp5LYnET",
        "outputId": "89f249ff-3d97-4f1c-f24f-031714cf9332"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4998 - loss: 0.6944 - val_accuracy: 0.4700 - val_loss: 0.6956\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5026 - loss: 0.6918 - val_accuracy: 0.5050 - val_loss: 0.6975\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5278 - loss: 0.6883 - val_accuracy: 0.4800 - val_loss: 0.6966\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5648 - loss: 0.6853 - val_accuracy: 0.4850 - val_loss: 0.6995\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5601 - loss: 0.6817 - val_accuracy: 0.4800 - val_loss: 0.7039\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5732 - loss: 0.6772 - val_accuracy: 0.4900 - val_loss: 0.7067\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5521 - loss: 0.6837 - val_accuracy: 0.4550 - val_loss: 0.7075\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5719 - loss: 0.6726 - val_accuracy: 0.4500 - val_loss: 0.7127\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5572 - loss: 0.6808 - val_accuracy: 0.4700 - val_loss: 0.7059\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5772 - loss: 0.6733 - val_accuracy: 0.4700 - val_loss: 0.7075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWPfGnVfYrFr",
        "outputId": "3e8c8cb1-aa9d-4ac2-d19a-987d13ccba1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4585 - loss: 0.7132 \n",
            "Test Accuracy: 0.4700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN forward propagation\n",
        "\n",
        "RNN forward propagation involves computing hidden states and outputs over a sequence using shared weights. This mechanism gives RNNs the ability to model sequential and time-dependent data effectively."
      ],
      "metadata": {
        "id": "_B_heyn9ZY4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "lfVoMv8FYtcb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 4    # Size of input vector (features)\n",
        "hidden_size = 5   # Size of hidden state\n",
        "output_size = 2   # Size of output vector\n",
        "timesteps = 6     # Length of input sequence"
      ],
      "metadata": {
        "id": "7tw3NolwZyWY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dummy input sequence (batch size = 1 for simplicity)\n",
        "np.random.seed(0)\n",
        "x = np.random.randn(timesteps, input_size)"
      ],
      "metadata": {
        "id": "xfB8sPmQZ0RU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and biases\n",
        "Wxh = np.random.randn(hidden_size, input_size)   # Input to hidden\n",
        "Whh = np.random.randn(hidden_size, hidden_size)  # Hidden to hidden\n",
        "Why = np.random.randn(output_size, hidden_size)  # Hidden to output"
      ],
      "metadata": {
        "id": "abcOFDcKZ3H2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bh = np.zeros((hidden_size, 1))  # Bias for hidden layer\n",
        "by = np.zeros((output_size, 1))  # Bias for output layer"
      ],
      "metadata": {
        "id": "OHMaVJyTZ5vY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the initial hidden state\n",
        "h_prev = np.zeros((hidden_size, 1))"
      ],
      "metadata": {
        "id": "gLZkoxn4Z7js"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store all hidden states and outputs\n",
        "hidden_states = []\n",
        "outputs = []"
      ],
      "metadata": {
        "id": "IEpKCtCUZ9or"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward propagation through time\n",
        "for t in range(timesteps):\n",
        "    xt = x[t].reshape(-1, 1)  # Shape (input_size, 1)\n",
        "\n",
        "    # Hidden state calculation\n",
        "    ht = np.tanh(np.dot(Wxh, xt) + np.dot(Whh, h_prev) + bh)\n",
        "\n",
        "    # Output calculation\n",
        "    yt = np.dot(Why, ht) + by\n",
        "\n",
        "    # Store results\n",
        "    hidden_states.append(ht)\n",
        "    outputs.append(yt)\n",
        "\n",
        "    # Update hidden state for next time step\n",
        "    h_prev = ht"
      ],
      "metadata": {
        "id": "O2YuiLJ4Z_iE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert outputs to numpy arrays for easier viewing\n",
        "outputs = np.array(outputs).squeeze()"
      ],
      "metadata": {
        "id": "cV7hj9x4aBs2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final output from RNN (one for each timestep):\\n\", outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F42y1qxzaDyr",
        "outputId": "d3e4f5bb-ab47-4d84-da23-6e2168d370a8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final output from RNN (one for each timestep):\n",
            " [[ 1.36210111 -0.04806836]\n",
            " [-0.38264111  1.23505342]\n",
            " [ 0.47215486 -1.39426624]\n",
            " [-0.66213135  2.32535818]\n",
            " [ 2.92316993  0.1776373 ]\n",
            " [-2.84506174 -0.23812638]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Sentiment Analysis:\n",
        "\n",
        "\n",
        "Sentiment analysis is a Natural Language Processing (NLP) task that involves determining the emotional tone behind a body of text. It is commonly used in applications such as product reviews, social media monitoring, and customer feedback analysis.\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are well-suited for sentiment analysis because they can process and learn from sequential data such as text. In Keras, RNN layers like SimpleRNN, LSTM, or GRU can be used to capture the contextual information from a sequence of words.\n",
        "\n",
        "\n",
        "## RNN Architecture for Sentiment Analysis\n",
        "\n",
        "- **Embedding Layer**: Converts word indices to dense vectors of fixed size.\n",
        "- **SimpleRNN Layer**: Processes the embedded sequence one step at a time and maintains a hidden state.\n",
        "- **Dense Output Layer**: Produces a binary prediction (positive or negative sentiment).\n",
        "\n",
        "## Benefits of Using RNN for Sentiment Analysis\n",
        "\n",
        "- Maintains context from earlier parts of the text due to its hidden state mechanism.\n",
        "- Learns the structure and patterns of language over sequences.\n",
        "- Outperforms traditional methods like bag-of-words in capturing word order and context.\n",
        "\n",
        "## Limitations\n",
        "\n",
        "- Standard RNNs may suffer from vanishing gradients and struggle with long sequences.\n",
        "- Better alternatives like LSTM and GRU are often preferred in practice for deeper context retention.\n",
        "\n",
        "## Summary\n",
        "\n",
        "RNNs in Keras provide a powerful and flexible way to perform sentiment analysis on sequential text data. While simple RNNs can work for short sequences, LSTMs or GRUs are usually recommended for improved performance on longer texts.\n"
      ],
      "metadata": {
        "id": "_ON-8ib4aoKL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vR6C9i-fyLvG"
      },
      "outputs": [],
      "source": [
        "docs = [\n",
        "    'go india',\n",
        "    'india india',\n",
        "    'hip hip hurray',\n",
        "    'jeetega bhai jeetega india jeetega',\n",
        "    'bharat mata ki jai',\n",
        "    'kohli kohli',\n",
        "    'sachin sachin',\n",
        "    'dhoni dhoni',\n",
        "    'modi ji ki jai',\n",
        "    'inquilab zindabad'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding"
      ],
      "metadata": {
        "id": "xRzvJNh1mRQW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and summarize the model\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Always +1 for reserved 0 index\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=2, input_length=5))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "2IhkPg6YmRYT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "4f30bf04-b7fc-4069-cbd3-077ba1714dfd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy compile and prediction\n",
        "model.compile(optimizer='adam', loss='mse')  # 'accuracy' is not a loss function\n",
        "pred = model.predict(sequences)\n",
        "print(\"Predictions shape:\", pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP5g_Tmin4AG",
        "outputId": "b0e31911-c574-409c-e37a-6b01ddf83fba"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "Predictions shape: (10, 5, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
      ],
      "metadata": {
        "id": "lOv8NrFFmRcE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
      ],
      "metadata": {
        "id": "KG1RqcLnmRkA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=50)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=50)"
      ],
      "metadata": {
        "id": "ETWEOn4wmRzd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=2, input_length=50))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "R68ghDfNmSAC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "ooYWO2NwoKoQ",
        "outputId": "ebe07fd6-3170-4099-9370-8c1dd141fd97"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "yrM0IXVamPLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71ba9044-d7ec-40fc-a6bd-6e04cf6d08c1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.5208 - loss: 0.6879 - val_accuracy: 0.7700 - val_loss: 0.4825\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.8018 - loss: 0.4366 - val_accuracy: 0.8157 - val_loss: 0.4137\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.8577 - loss: 0.3368 - val_accuracy: 0.7900 - val_loss: 0.4755\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.8892 - loss: 0.2807 - val_accuracy: 0.8053 - val_loss: 0.4723\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9035 - loss: 0.2474 - val_accuracy: 0.8016 - val_loss: 0.4688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation RNN\n",
        "\n",
        "Backpropagation in RNNs is an extension of the backpropagation algorithm used in feedforward neural networks. It is called **Backpropagation Through Time (BPTT)** because RNNs handle sequential data where the output at each time step depends not only on the current input but also on previous inputs.\n",
        "\n",
        "## Why?\n",
        "\n",
        "Since RNNs have a temporal dimension, the weights are shared across time steps. Hence, to train RNNs, we need to propagate the error through each time step in reverse order — this process is known as **Backpropagation Through Time**.\n",
        "\n",
        "## Steps\n",
        "\n",
        "1. **Forward Pass**:\n",
        "   - For each time step \\( t \\), compute the hidden state \\( h_t \\) and the output \\( y_t \\) using:\n",
        "     \\[\n",
        "     h_t = \\tanh(W_{hh} h_{t-1} + W_{xh} x_t + b_h)\n",
        "     \\]\n",
        "     \\[\n",
        "     y_t = W_{hy} h_t + b_y\n",
        "     \\]\n",
        "\n",
        "2. **Loss Calculation**:\n",
        "   - Compute the total loss over all time steps:\n",
        "     \\[\n",
        "     L = \\sum_{t=1}^{T} \\mathcal{L}(y_t, \\hat{y}_t)\n",
        "     \\]\n",
        "\n",
        "3. **Backward Pass (BPTT)**:\n",
        "   - Compute the gradients of the loss with respect to weights by applying the chain rule backward through time.\n",
        "   - Since the same weights are used at every time step, the gradients accumulate over time:\n",
        "     \\[\n",
        "     \\frac{\\partial L}{\\partial W} = \\sum_{t=1}^{T} \\frac{\\partial L_t}{\\partial W}\n",
        "     \\]\n",
        "\n",
        "## Challenges in BPTT\n",
        "\n",
        "- **Vanishing Gradient**: Gradients shrink as they are propagated backward, leading to poor learning in long sequences.\n",
        "- **Exploding Gradient**: Gradients grow exponentially, causing unstable training.\n",
        "\n",
        "## Solutions\n",
        "\n",
        "- **Gradient Clipping**: Caps the gradients during backpropagation to avoid explosion.\n",
        "- **Use of LSTM/GRU**: Gated architectures help in retaining long-term dependencies better than vanilla RNNs.\n",
        "\n",
        "## Summary\n",
        "\n",
        "Backpropagation in RNNs involves computing gradients across time steps due to the sequential nature of the data. BPTT is the adapted algorithm that handles temporal dependencies and trains the shared weights across time effectively.\n"
      ],
      "metadata": {
        "id": "MGHjkEGhT7QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "tVKEJ0cYc-by"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "2SwTFtvxdDbH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "-Yv-YDscUW57"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dsigmoid(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n"
      ],
      "metadata": {
        "id": "Y2HCKuMdUawC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tanh(x):\n",
        "    return np.tanh(x)"
      ],
      "metadata": {
        "id": "r19swHUNUdEI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dtanh(x):\n",
        "    return 1 - np.tanh(x) ** 2"
      ],
      "metadata": {
        "id": "qSbXZjk0Ue9A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset: input sequence of 3 time steps, each with 2 features\n",
        "X = [np.array([[1], [0]]), np.array([[0], [1]]), np.array([[1], [1]])]\n",
        "Y = [np.array([[1]]), np.array([[0]]), np.array([[1]])]"
      ],
      "metadata": {
        "id": "47qO_9AGUgnr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN parameters\n",
        "input_size = 2\n",
        "hidden_size = 4\n",
        "output_size = 1\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "k1If3ONLUrqo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weight initialization\n",
        "Wxh = np.random.randn(hidden_size, input_size) * 0.01  # input to hidden\n",
        "Whh = np.random.randn(hidden_size, hidden_size) * 0.01  # hidden to hidden\n",
        "Why = np.random.randn(output_size, hidden_size) * 0.01  # hidden to output\n",
        "bh = np.zeros((hidden_size, 1))  # hidden bias\n",
        "by = np.zeros((output_size, 1))  # output bias"
      ],
      "metadata": {
        "id": "E9X5f9EQUt3L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training for 1 epoch (can loop over multiple epochs)\n",
        "h_prev = np.zeros((hidden_size, 1))\n",
        "hs, ys, ps = {}, {}, {}\n",
        "hs[-1] = h_prev\n",
        "loss = 0"
      ],
      "metadata": {
        "id": "2SnrzOXyU1JI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Pass\n",
        "for t in range(len(X)):\n",
        "    x_t = X[t]\n",
        "    hs[t] = tanh(np.dot(Wxh, x_t) + np.dot(Whh, hs[t-1]) + bh)\n",
        "    ys[t] = np.dot(Why, hs[t]) + by\n",
        "    ps[t] = sigmoid(ys[t])\n",
        "    loss += 0.5 * (ps[t] - Y[t]) ** 2  # MSE Loss"
      ],
      "metadata": {
        "id": "TPsDMlc2U3Pj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initial Loss:\", np.sum(loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8vbdiEHU7eQ",
        "outputId": "35f22f83-52fb-4956-8d73-2ea6ad1ce4fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Loss: 0.7499675916291635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward Pass (BPTT)\n",
        "dWxh = np.zeros_like(Wxh)\n",
        "dWhh = np.zeros_like(Whh)\n",
        "dWhy = np.zeros_like(Why)\n",
        "dbh = np.zeros_like(bh)\n",
        "dby = np.zeros_like(by)\n",
        "dh_next = np.zeros_like(hs[0])"
      ],
      "metadata": {
        "id": "XNw_vR-5U-Gj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in reversed(range(len(X))):\n",
        "    dy = (ps[t] - Y[t]) * dsigmoid(ys[t])  # output error\n",
        "    dWhy += np.dot(dy, hs[t].T)\n",
        "    dby += dy\n",
        "\n",
        "    dh = np.dot(Why.T, dy) + dh_next  # backprop into h\n",
        "    dh_raw = dh * dtanh(hs[t])\n",
        "    dbh += dh_raw\n",
        "    dWxh += np.dot(dh_raw, X[t].T)\n",
        "    dWhh += np.dot(dh_raw, hs[t-1].T)\n",
        "    dh_next = np.dot(Whh.T, dh_raw)"
      ],
      "metadata": {
        "id": "yB93kK5YVAmY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clip gradients to prevent exploding gradients\n",
        "for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
        "    np.clip(dparam, -1, 1, out=dparam)"
      ],
      "metadata": {
        "id": "LX82F-dkVFO4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update weights\n",
        "Wxh -= learning_rate * dWxh\n",
        "Whh -= learning_rate * dWhh\n",
        "Why -= learning_rate * dWhy\n",
        "bh -= learning_rate * dbh\n",
        "by -= learning_rate * dby"
      ],
      "metadata": {
        "id": "-JLhNpXqVHUo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Updated weights and biases after 1 BPTT step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puc9sOw9VLJp",
        "outputId": "7b8bff2f-17ee-426b-d775-4e599ecfb5fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated weights and biases after 1 BPTT step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vlw6N6dkVNpE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}